"""
This type stub file was generated by pyright.
"""

import logging
import sys
import string
import inspect
from contextlib import contextmanager

unicode_srctypes = ...
lgr = ...
platform_system = ...
on_windows = ...
on_osx = ...
on_linux = ...
on_msys_tainted_paths = ...
def get_linux_distribution(): # -> tuple[Unknown | str, str | Unknown, Unknown | Literal['']]:
    """Compatibility wrapper for {platform,distro}.linux_distribution().
    """
    ...

on_debian_wheezy = ...
CMD_MAX_ARG_HARDCODED = ...
CMD_MAX_ARG = ...
if sys.version_info[: 2] == (3, 4):
    CMD_MAX_ARG = ...
CMD_MAX_ARG = ...
if hasattr(inspect, "getfullargspec"):
    ArgSpecFake = ...
    def getargspec(func): # -> ArgSpecFake:
        ...
    
else:
    getargspec = ...
def get_func_kwargs_doc(func):
    """ Provides args for a function

    Parameters
    ----------
    func: str
      name of the function from which args are being requested

    Returns
    -------
    list
      of the args that a function takes in
    """
    ...

def any_re_search(regexes, value): # -> bool:
    """Return if any of regexes (list or str) searches succesfully for value"""
    ...

def not_supported_on_windows(msg=...): # -> None:
    """A little helper to be invoked to consistently fail whenever functionality is
    not supported (yet) on Windows
    """
    ...

def shortened_repr(value, l=...): # -> str:
    ...

def __auto_repr__(obj): # -> LiteralString:
    ...

def auto_repr(cls):
    """Decorator for a class to assign it an automagic quick and dirty __repr__

    It uses public class attributes to prepare repr of a class

    Original idea: http://stackoverflow.com/a/27799004/1265472
    """
    ...

def is_interactive(): # -> bool:
    """Return True if all in/outs are open and tty.

    Note that in a somewhat abnormal case where e.g. stdin is explicitly
    closed, and any operation on it would raise a
    `ValueError("I/O operation on closed file")` exception, this function
    would just return False, since the session cannot be used interactively.
    """
    ...

def get_ipython_shell(): # -> None:
    """Detect if running within IPython and returns its `ip` (shell) object

    Returns None if not under ipython (no `get_ipython` function)
    """
    ...

def md5sum(filename): # -> Any:
    """Compute an MD5 sum for the given file
    """
    ...

def sorted_files(dout): # -> list[Unknown]:
    """Return a (sorted) list of files under dout
    """
    ...

_encoded_dirsep = ...
_VCS_REGEX = ...
_DATALAD_REGEX = ...
def find_files(regex, topdir=..., exclude=..., exclude_vcs=..., exclude_datalad=..., dirs=...): # -> Generator[str, None, None]:
    """Generator to find files matching regex

    Parameters
    ----------
    regex: basestring
    exclude: basestring, optional
      Matches to exclude
    exclude_vcs:
      If True, excludes commonly known VCS subdirectories.  If string, used
      as regex to exclude those files (regex: `%r`)
    exclude_datalad:
      If True, excludes files known to be datalad meta-data files (e.g. under
      .datalad/ subdirectory) (regex: `%r`)
    topdir: basestring, optional
      Directory where to search
    dirs: bool, optional
      Whether to match directories as well as files
    """
    ...

def expandpath(path, force_absolute=...):
    """Expand all variables and user handles in a path.

    By default return an absolute path
    """
    ...

def posix_relpath(path, start=...): # -> str:
    """Behave like os.path.relpath, but always return POSIX paths...

    on any platform."""
    ...

def is_explicit_path(path): # -> Literal[True]:
    """Return whether a path explicitly points to a location

    Any absolute path, or relative path starting with either '../' or
    './' is assumed to indicate a location on the filesystem. Any other
    path format is not considered explicit."""
    ...

def rotree(path, ro=..., chmod_files=...): # -> None:
    """To make tree read-only or writable

    Parameters
    ----------
    path : string
      Path to the tree/directory to chmod
    ro : bool, optional
      Whether to make it R/O (default) or RW
    chmod_files : bool, optional
      Whether to operate also on files (not just directories)
    """
    ...

def rmtree(path, chmod_files=..., children_only=..., *args, **kwargs): # -> None:
    """To remove git-annex .git it is needed to make all files and directories writable again first

    Parameters
    ----------
    chmod_files : string or bool, optional
       Whether to make files writable also before removal.  Usually it is just
       a matter of directories to have write permissions.
       If 'auto' it would chmod files on windows by default
    children_only : bool, optional
       If set, all files and subdirectories would be removed while the path
       itself (must be a directory) would be preserved
    `*args` :
    `**kwargs` :
       Passed into shutil.rmtree call
    """
    ...

def rmdir(path, *args, **kwargs): # -> None:
    """os.rmdir with our optional checking for open files"""
    ...

def get_open_files(path, log_open=...): # -> dict[Unknown, Unknown]:
    """Get open files under a path

    Parameters
    ----------
    path : str
      File or directory to check for open files under
    log_open : bool or int
      If set - logger level to use

    Returns
    -------
    dict
      path : pid

    """
    ...

_assert_no_open_files_cfg = ...
if _assert_no_open_files_cfg:
    def assert_no_open_files(path): # -> None:
        ...
    
else:
    def assert_no_open_files(*args, **kwargs): # -> None:
        ...
    
def rmtemp(f, *args, **kwargs): # -> None:
    """Wrapper to centralize removing of temp files so we could keep them around

    It will not remove the temporary file/directory if DATALAD_TESTS_TEMP_KEEP
    environment variable is defined
    """
    ...

def file_basename(name, return_ext=...): # -> tuple[str, Unknown] | str:
    """
    Strips up to 2 extensions of length up to 4 characters and starting with alpha
    not a digit, so we could get rid of .tar.gz etc
    """
    ...

def escape_filename(filename):
    """Surround filename in "" and escape " in the filename
    """
    ...

def encode_filename(filename): # -> bytes:
    """Encode unicode filename
    """
    ...

def decode_input(s): # -> str:
    """Given input string/bytes, decode according to stdin codepage (or UTF-8)
    if not defined

    If fails -- issue warning and decode allowing for errors
    being replaced
    """
    ...

if on_windows:
    def lmtime(filepath, mtime): # -> None:
        """Set mtime for files.  On Windows a merely adapter to os.utime
        """
        ...
    
else:
    def lmtime(filepath, mtime): # -> None:
        """Set mtime for files, while not de-referencing symlinks.

        To overcome absence of os.lutime

        Works only on linux and OSX ATM
        """
        ...
    
def ensure_tuple_or_list(obj): # -> list[Unknown] | tuple[Unknown]:
    """Given an object, wrap into a tuple if not list or tuple
    """
    ...

def ensure_iter(s, cls, copy=..., iterate=...):
    """Given not a list, would place it into a list. If None - empty list is returned

    Parameters
    ----------
    s: list or anything
    cls: class
      Which iterable class to ensure
    copy: bool, optional
      If correct iterable is passed, it would generate its shallow copy
    iterate: bool, optional
      If it is not a list, but something iterable (but not a str)
      iterate over it.
    """
    ...

def ensure_list(s, copy=..., iterate=...):
    """Given not a list, would place it into a list. If None - empty list is returned

    Parameters
    ----------
    s: list or anything
    copy: bool, optional
      If list is passed, it would generate a shallow copy of the list
    iterate: bool, optional
      If it is not a list, but something iterable (but not a str)
      iterate over it.
    """
    ...

def ensure_list_from_str(s, sep=...): # -> list[Unknown] | None:
    """Given a multiline string convert it to a list of return None if empty

    Parameters
    ----------
    s: str or list
    """
    ...

def ensure_dict_from_str(s, **kwargs): # -> dict[Unknown, Unknown] | None:
    """Given a multiline string with key=value items convert it to a dictionary

    Parameters
    ----------
    s: str or dict

    Returns None if input s is empty
    """
    ...

def ensure_bytes(s, encoding=...): # -> bytes:
    """Convert/encode unicode string to bytes.

    If `s` isn't a string, return it as is.

    Parameters
    ----------
    encoding: str, optional
      Encoding to use.  "utf-8" is the default
    """
    ...

def ensure_unicode(s, encoding=..., confidence=...): # -> str:
    """Convert/decode bytestring to unicode.

    If `s` isn't a bytestring, return it as is.

    Parameters
    ----------
    encoding: str, optional
      Encoding to use.  If None, "utf-8" is tried, and then if not a valid
      UTF-8, encoding will be guessed
    confidence: float, optional
      A value between 0 and 1, so if guessing of encoding is of lower than
      specified confidence, ValueError is raised
    """
    ...

def ensure_bool(s): # -> bool:
    """Convert value into boolean following convention for strings

    to recognize on,True,yes as True, off,False,no as False
    """
    ...

def as_unicode(val, cast_types=...): # -> str:
    """Given an arbitrary value, would try to obtain unicode value of it
    
    For unicode it would return original value, for python2 str or python3
    bytes it would use ensure_unicode, for None - an empty (unicode) string,
    and for any other type (see `cast_types`) - would apply the unicode 
    constructor.  If value is not an instance of `cast_types`, TypeError
    is thrown
    
    Parameters
    ----------
    cast_types: type
      Which types to cast to unicode by providing to constructor
    """
    ...

def unique(seq, key=..., reverse=...): # -> list[Unknown]:
    """Given a sequence return a list only with unique elements while maintaining order

    This is the fastest solution.  See
    https://www.peterbe.com/plog/uniqifiers-benchmark
    and
    http://stackoverflow.com/a/480227/1265472
    for more information.
    Enhancement -- added ability to compare for uniqueness using a key function

    Parameters
    ----------
    seq:
      Sequence to analyze
    key: callable, optional
      Function to call on each element so we could decide not on a full
      element, but on its member etc
    reverse: bool, optional
      If True, uniqueness checked in the reverse order, so that the later ones
      will take the order
    """
    ...

def all_same(items): # -> bool:
    """Quick check if all items are the same.

    Identical to a check like len(set(items)) == 1 but
    should be more efficient while working on generators, since would
    return False as soon as any difference detected thus possibly avoiding
    unnecessary evaluations
    """
    ...

def map_items(func, v):
    """A helper to apply `func` to all elements (keys and values) within dict

    No type checking of values passed to func is done, so `func`
    should be resilient to values which it should not handle

    Initial usecase - apply_recursive(url_fragment, ensure_unicode)
    """
    ...

def partition(items, predicate=...): # -> tuple[Generator[Unknown, None, None], Generator[Unknown, None, None]]:
    """Partition `items` by `predicate`.

    Parameters
    ----------
    items : iterable
    predicate : callable
        A function that will be mapped over each element in `items`. The
        elements will partitioned based on whether the return value is false or
        true.

    Returns
    -------
    A tuple with two generators, the first for 'false' items and the second for
    'true' ones.

    Notes
    -----
    Taken from Peter Otten's snippet posted at
    https://nedbatchelder.com/blog/201306/filter_a_list_into_two_parts.html
    """
    ...

def generate_chunks(container, size): # -> Generator[Unknown, None, None]:
    """Given a container, generate chunks from it with size up to `size`
    """
    ...

def generate_file_chunks(files, cmd=...): # -> Generator[Unknown, None, None]:
    """Given a list of files, generate chunks of them to avoid exceding cmdline length

    Parameters
    ----------
    files: list of str
    cmd: str or list of str, optional
      Command to account for as well
    """
    ...

def saved_generator(gen): # -> tuple[Generator[Unknown, None, None], Generator[Unknown, None, None]]:
    """Given a generator returns two generators, where 2nd one just replays

    So the first one would be going through the generated items and 2nd one
    would be yielding saved items
    """
    ...

def better_wraps(to_be_wrapped): # -> (to_be_wrapper: Unknown, instance: Unknown, args: Unknown, kwargs: Unknown) -> Unknown:
    """Decorator to replace `functools.wraps`

    This is based on `wrapt` instead of `functools` and in opposition to `wraps`
    preserves the correct signature of the decorated function.
    It is written with the intention to replace the use of `wraps` without any
    need to rewrite the actual decorators.
    """
    ...

def optional_args(decorator): # -> (*args: Unknown, **kwargs: Unknown) -> (Unknown | ((f: Unknown) -> Unknown)):
    """allows a decorator to take optional positional and keyword arguments.
        Assumes that taking a single, callable, positional argument means that
        it is decorating a function, i.e. something like this::

            @my_decorator
            def function(): pass

        Calls decorator with decorator(f, `*args`, `**kwargs`)"""
    ...

def get_tempfile_kwargs(tkwargs=..., prefix=..., wrapped=...): # -> dict[Unknown, Unknown]:
    """Updates kwargs to be passed to tempfile. calls depending on env vars
    """
    ...

@optional_args
def line_profile(func): # -> _Wrapped[(...), Unknown, (*args: Unknown, **kwargs: Unknown), Unknown]:
    """Q&D helper to line profile the function and spit out stats
    """
    ...

def never_fail(f): # -> _Wrapped[(...), Unknown, (*args: Unknown, **kwargs: Unknown), Unknown | None]:
    """Assure that function never fails -- all exceptions are caught

    Returns `None` if function fails internally.
    """
    ...

@contextmanager
def nothing_cm(): # -> Generator[None, None, None]:
    """Just a dummy cm to programmically switch context managers"""
    ...

@contextmanager
def swallow_outputs(): # -> Generator[StringIOAdapter, None, None]:
    """Context manager to help consuming both stdout and stderr, and print()

    stdout is available as cm.out and stderr as cm.err whenever cm is the
    yielded context manager.
    Internally uses temporary files to guarantee absent side-effects of swallowing
    into StringIO which lacks .fileno.

    print mocking is necessary for some uses where sys.stdout was already bound
    to original sys.stdout, thus mocking it later had no effect. Overriding
    print function had desired effect
    """
    class StringIOAdapter:
        """Little adapter to help getting out/err values
        """
        ...
    
    

@contextmanager
def swallow_logs(new_level=..., file_=..., name=...): # -> Generator[StringIOAdapter, None, None]:
    """Context manager to consume all logs.

    """
    class StringIOAdapter:
        """Little adapter to help getting out values

        And to stay consistent with how swallow_outputs behaves
        """
        ...
    
    

@contextmanager
def disable_logger(logger=...): # -> Generator[Logger | Unknown, None, None]:
    """context manager to temporarily disable logging

    This is to provide one of swallow_logs' purposes without unnecessarily
    creating temp files (see gh-1865)

    Parameters
    ----------
    logger: Logger
        Logger whose handlers will be ordered to not log anything.
        Default: datalad's topmost Logger ('datalad')
    """
    class NullFilter(logging.Filter):
        """Filter class to reject all records
        """
        ...
    
    

_sys_excepthook = ...
def setup_exceptionhook(ipython=...): # -> None:
    """Overloads default sys.excepthook with our exceptionhook handler.

       If interactive, our exceptionhook handler will invoke
       pdb.post_mortem; if not interactive, then invokes default handler.
    """
    ...

def ensure_dir(*args):
    """Make sure directory exists.

    Joins the list of arguments to an os-specific path to the desired
    directory and creates it, if it not exists yet.
    """
    ...

def updated(d, update):
    """Return a copy of the input with the 'update'

    Primarily for updating dictionaries
    """
    ...

_pwd_mode = ...
def getpwd(): # -> str | None:
    """Try to return a CWD without dereferencing possible symlinks

    This function will try to use PWD environment variable to provide a current
    working directory, possibly with some directories along the path being
    symlinks to other directories.  Unfortunately, PWD is used/set only by the
    shell and such functions as `os.chdir` and `os.getcwd` nohow use or modify
    it, thus `os.getcwd()` returns path with links dereferenced.

    While returning current working directory based on PWD env variable we
    verify that the directory is the same as `os.getcwd()` after resolving all
    symlinks.  If that verification fails, we fall back to always use
    `os.getcwd()`.

    Initial decision to either use PWD env variable or os.getcwd() is done upon
    the first call of this function.
    """
    ...

class chpwd:
    """Wrapper around os.chdir which also adjusts environ['PWD']

    The reason is that otherwise PWD is simply inherited from the shell
    and we have no ability to assess directory path without dereferencing
    symlinks.

    If used as a context manager it allows to temporarily change directory
    to the given path
    """
    def __init__(self, path, mkdir=..., logsuffix=...) -> None:
        ...
    
    def __enter__(self): # -> None:
        ...
    
    def __exit__(self, exc_type, exc_val, exc_tb): # -> None:
        ...
    


def dlabspath(path, norm=...):
    """Symlinks-in-the-cwd aware abspath

    os.path.abspath relies on os.getcwd() which would not know about symlinks
    in the path

    TODO: we might want to norm=True by default to match behavior of
    os .path.abspath?
    """
    ...

def with_pathsep(path):
    """Little helper to guarantee that path ends with /"""
    ...

def get_path_prefix(path, pwd=...): # -> str:
    """Get path prefix (for current directory)

    Returns relative path to the topdir, if we are under topdir, and if not
    absolute path to topdir.  If `pwd` is not specified - current directory
    assumed
    """
    ...

def path_startswith(path, prefix):
    """Return True if path starts with prefix path

    Parameters
    ----------
    path: str
    prefix: str
    """
    ...

def path_is_subpath(path, prefix): # -> Literal[False]:
    """Return True if path is a subpath of prefix

    It will return False if path == prefix.

    Parameters
    ----------
    path: str
    prefix: str
    """
    ...

def knows_annex(path): # -> bool:
    """Returns whether at a given path there is information about an annex

    It is just a thin wrapper around GitRepo.is_with_annex() classmethod
    which also checks for `path` to exist first.

    This includes actually present annexes, but also uninitialized ones, or
    even the presence of a remote annex branch.
    """
    ...

@contextmanager
def make_tempfile(content=..., wrapped=..., **tkwargs): # -> Generator[str, None, None]:
    """Helper class to provide a temporary file name and remove it at the end (context manager)

    Parameters
    ----------
    mkdir : bool, optional (default: False)
        If True, temporary directory created using tempfile.mkdtemp()
    content : str or bytes, optional
        Content to be stored in the file created
    wrapped : function, optional
        If set, function name used to prefix temporary file name
    `**tkwargs`:
        All other arguments are passed into the call to tempfile.mk{,d}temp(),
        and resultant temporary filename is passed as the first argument into
        the function t.  If no 'prefix' argument is provided, it will be
        constructed using module and function names ('.' replaced with
        '_').

    To change the used directory without providing keyword argument 'dir' set
    DATALAD_TESTS_TEMP_DIR.

    Examples
    --------
        >>> from os.path import exists
        >>> from datalad.utils import make_tempfile
        >>> with make_tempfile() as fname:
        ...    k = open(fname, 'w').write('silly test')
        >>> assert not exists(fname)  # was removed

        >>> with make_tempfile(content="blah") as fname:
        ...    assert open(fname).read() == "blah"
    """
    ...

def get_timestamp_suffix(time_=..., prefix=...): # -> str:
    """Return a time stamp (full date and time up to second)

    primarily to be used for generation of log files names
    """
    ...

def get_logfilename(dspath, cmd=...): # -> str:
    """Return a filename to use for logging under a dataset/repository

    directory would be created if doesn't exist, but dspath must exist
    and be a directory
    """
    ...

def get_trace(edges, start, end, trace=...): # -> list[Unknown] | None:
    """Return the trace/path to reach a node in a tree.

    Parameters
    ----------
    edges : sequence(2-tuple)
      The tree given by a sequence of edges (parent, child) tuples. The
      nodes can be identified by any value and data type that supports
      the '==' operation.
    start :
      Identifier of the start node. Must be present as a value in the parent
      location of an edge tuple in order to be found.
    end :
      Identifier of the target/end node. Must be present as a value in the child
      location of an edge tuple in order to be found.
    trace : list
      Mostly useful for recursive calls, and used internally.

    Returns
    -------
    None or list
      Returns a list with the trace to the target (the starts and the target
      are not included in the trace, hence if start and end are directly connected
      an empty list is returned), or None when no trace to the target can be found,
      or start and end are identical.
    """
    ...

def get_dataset_root(path): # -> str | None:
    """Return the root of an existent dataset containing a given path

    The root path is returned in the same absolute or relative form
    as the input argument. If no associated dataset exists, or the
    input path doesn't exist, None is returned.

    If `path` is a symlink or something other than a directory, its
    the root dataset containing its parent directory will be reported.
    If none can be found, at a symlink at `path` is pointing to a
    dataset, `path` itself will be reported as the root.
    """
    ...

def try_multiple(ntrials, exception, base, f, *args, **kwargs): # -> None:
    """Call f multiple times making exponentially growing delay between the calls"""
    ...

@optional_args
def try_multiple_dec(f, ntrials=..., duration=..., exceptions=..., increment_type=...): # -> _Wrapped[(...), Unknown, (*args: Unknown, **kwargs: Unknown), Unknown | None]:
    """Decorator to try function multiple times.

    Main purpose is to decorate functions dealing with removal of files/directories
    and which might need a few seconds to work correctly on Windows which takes
    its time to release files/directories.

    Parameters
    ----------
    ntrials: int, optional
    duration: float, optional
      Seconds to sleep before retrying.
    increment_type: {None, 'exponential'}
      Note that if it is exponential, duration should typically be > 1.0
      so it grows with higher power

    """
    ...

@try_multiple_dec
def unlink(f): # -> None:
    """'Robust' unlink.  Would try multiple times

    On windows boxes there is evidence for a latency of more than a second
    until a file is considered no longer "in-use".
    WindowsError is not known on Linux, and if IOError or any other
    exception
    is thrown then if except statement has WindowsError in it -- NameError
    also see gh-2533
    """
    ...

def slash_join(base, extension): # -> LiteralString:
    """Join two strings with a '/', avoiding duplicate slashes

    If any of the strings is None the other is returned as is.
    """
    ...

def safe_print(s): # -> None:
    """Print with protection against UTF-8 encoding errors"""
    ...

def open_r_encdetect(fname, readahead=...): # -> TextIOWrapper:
    """Return a file object in read mode with auto-detected encoding

    This is helpful when dealing with files of unknown encoding.

    Parameters
    ----------
    readahead: int, optional
      How many bytes to read for guessing the encoding type.  If
      negative - full file will be read
    """
    ...

def read_csv_lines(fname, dialect=..., readahead=..., **kwargs): # -> Generator[dict[Any, Any], None, None]:
    """A generator of dict records from a CSV/TSV

    Automatically guesses the encoding for each record to convert to UTF-8

    Parameters
    ----------
    fname: str
      Filename
    dialect: str, optional
      Dialect to specify to csv.reader. If not specified -- guessed from
      the file, if fails to guess, "excel-tab" is assumed
    readahead: int, optional
      How many bytes to read from the file to guess the type
    **kwargs
      Passed to `csv.reader`
    """
    ...

def import_modules(modnames, pkg, msg=..., log=...): # -> list[Unknown]:
    """Helper to import a list of modules without failing if N/A

    Parameters
    ----------
    modnames: list of str
      List of module names to import
    pkg: str
      Package under which to import
    msg: str, optional
      Message template for .format() to log at DEBUG level if import fails.
      Keys {module} and {package} will be provided and ': {exception}' appended
    log: callable, optional
      Logger call to use for logging messages
    """
    ...

def import_module_from_file(modpath, pkg=..., log=...): # -> ModuleType | Any:
    """Import provided module given a path

    TODO:
    - RF/make use of it in pipeline.py which has similar logic
    - join with import_modules above?

    Parameters
    ----------
    pkg: module, optional
       If provided, and modpath is under pkg.__path__, relative import will be
       used
    """
    ...

def get_encoding_info(): # -> OrderedDict[Literal['default', 'filesystem', 'locale.prefered'], str]:
    """Return a dictionary with various encoding/locale information"""
    ...

def get_envvars_info(): # -> OrderedDict[Unknown, Unknown]:
    ...

class SequenceFormatter(string.Formatter):
    """string.Formatter subclass with special behavior for sequences.

    This class delegates formatting of individual elements to another
    formatter object. Non-list objects are formatted by calling the
    delegate formatter's "format_field" method. List-like objects
    (list, tuple, set, frozenset) are formatted by formatting each
    element of the list according to the specified format spec using
    the delegate formatter and then joining the resulting strings with
    a separator (space by default).
    """
    def __init__(self, separator=..., element_formatter=..., *args, **kwargs) -> None:
        ...
    
    def format_element(self, elem, format_spec): # -> Any:
        """Format a single element

        For sequences, this is called once for each element in a
        sequence. For anything else, it is called on the entire
        object. It is intended to be overridden in subclases.
        """
        ...
    
    def format_field(self, value, format_spec): # -> str | Any:
        ...
    


class File:
    """Helper for a file entry in the create_tree/@with_tree

    It allows to define additional settings for entries
    """
    def __init__(self, name, executable=...) -> None:
        """

        Parameters
        ----------
        name : str
          Name of the file
        executable: bool, optional
          Make it executable
        """
        ...
    
    def __str__(self) -> str:
        ...
    


def create_tree_archive(path, name, load, overwrite=..., archives_leading_dir=...): # -> None:
    """Given an archive `name`, create under `path` with specified `load` tree
    """
    ...

def create_tree(path, tree, archives_leading_dir=..., remove_existing=...): # -> None:
    """Given a list of tuples (name, load) create such a tree

    if load is a tuple itself -- that would create either a subtree or an archive
    with that content and place it into the tree if name ends with .tar.gz
    """
    ...

def get_suggestions_msg(values, known, sep=...): # -> str:
    """Return a formatted string with suggestions for values given the known ones
    """
    ...

def bytes2human(n, format=...): # -> str:
    """
    Convert n bytes into a human readable string based on format.
    symbols can be either "customary", "customary_ext", "iec" or "iec_ext",
    see: http://goo.gl/kTQMs

      >>> from datalad.utils import bytes2human
      >>> bytes2human(1)
      '1.0 B'
      >>> bytes2human(1024)
      '1.0 KB'
      >>> bytes2human(1048576)
      '1.0 MB'
      >>> bytes2human(1099511627776127398123789121)
      '909.5 YB'

      >>> bytes2human(10000, "%(value).1f %(symbol)s/sec")
      '9.8 K/sec'

      >>> # precision can be adjusted by playing with %f operator
      >>> bytes2human(10000, format="%(value).5f %(symbol)s")
      '9.76562 K'

    Taken from: http://goo.gl/kTQMs and subsequently simplified
    Original Author: Giampaolo Rodola' <g.rodola [AT] gmail [DOT] com>
    License: MIT
    """
    ...

def quote_cmdlinearg(arg): # -> str:
    """Perform platform-appropriate argument quoting"""
    ...

def split_cmdline(s): # -> list[str] | list[Unknown]:
    """Perform platform-appropriate command line splitting.

    Identical to `shlex.split()` on non-windows platforms.

    Modified from https://stackoverflow.com/a/35900070
    """
    ...

def get_wrapped_class(wrapped): # -> Any:
    """Determine the command class a wrapped __call__ belongs to"""
    ...

assure_tuple_or_list = ...
assure_iter = ...
assure_list = ...
assure_list_from_str = ...
assure_dict_from_str = ...
assure_bytes = ...
assure_unicode = ...
assure_bool = ...
assure_dir = ...
