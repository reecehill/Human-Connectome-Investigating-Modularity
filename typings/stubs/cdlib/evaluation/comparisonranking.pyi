"""
This type stub file was generated by pyright.
"""

from typing import Callable

__all__ = ["elem", "ComparisonRanking"]
elem = ...
post_hoc = ...
class ComparisonRanking:
    def __init__(self, partitions: list) -> None:
        """
        Class that provides functionalities for the generation of Clustering objects w.r.t. a given set of fitness scores.

        :param partitions: a list of Clustering objects
        """
        ...
    
    def rank(self, comparison_function: Callable[[object, object], object]): # -> tuple[str, dict[Any, Any]]:
        """
        Computes the specified comparison function to all the Clustering objects for which a ranking is required.

        :param scoring_function: a fitness function from cdlib.evaluation
        :return: a tuple whose first element is the scoring_function name, while the second is a dictionary having as key the clustering name and as value the computed score.

        :Example:

        >>> import networkx as nx
        >>> from cdlib import evaluation
        >>> from cdlib import algorithms
        >>> g = nx.karate_club_graph()
        >>> coms = algorithms.louvain(g)
        >>> coms2 = algorithms.kclique(g, 2)
        >>> coms3 = algorithms.label_propagation(g)
        >>> rk = evaluation.ComparisonRanking([coms, coms2, coms3])
        >>> rk.rank(evaluation.overlapping_normalized_mutual_information_LFK)
        """
        ...
    
    def topsis(self) -> [list, None]:
        """
        The Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) is a multi-criteria decision analysis method.
        TOPSIS is based on the concept that the chosen alternative should have the shortest geometric distance from the positive ideal solution (PIS) and the longest geometric distance from the negative ideal solution (NIS).

        :return: a tuple whose first element is the ranking dictionary assigning a TOPSIS score to each Clustering object, while the second is None (to maintain coherence with friedman_ranking).

        :Example:

        >>> import networkx as nx
        >>> from cdlib import evaluation
        >>> from cdlib import algorithms
        >>> g = nx.karate_club_graph()
        >>> coms = algorithms.louvain(g)
        >>> coms2 = algorithms.kclique(g, 2)
        >>> coms3 = algorithms.label_propagation(g)
        >>> rk = evaluation.ComparisonRanking([coms, coms2, coms3])
        >>> rk.rank(evaluation.overlapping_normalized_mutual_information_LFK)
        >>> rk.rank(evaluation.overlapping_normalized_mutual_information_MGH)
        >>> rk.rank(evaluation.omega)
        >>> rnk, _ = rk.topsis()

        :References:

        1. Hwang, C.L.; Yoon, K. (1981). Multiple Attribute Decision Making: Methods and Applications. New York: Springer-Verlag.
        2. Yoon, K. (1987). "A reconciliation among discrete compromise situations". Journal of the Operational Research Society. 38 (3): 277–286. doi:10.1057/jors.1987.44.
        """
        ...
    
    def friedman_ranking(self) -> [list, float]:
        """
        Performs a Friedman ranking test.
        Tests the hypothesis that in a set of k dependent samples groups (where k >= 2) at least two of the groups represent populations with different median values.


        :return: a tuple whose first element is a dictionary assigning a rank to each Clustering object, while the second is the p-value associated to the ranking.

        :Example:

        >>> import networkx as nx
        >>> from cdlib import evaluation
        >>> from cdlib import algorithms
        >>> g = nx.karate_club_graph()
        >>> coms = algorithms.louvain(g)
        >>> coms2 = algorithms.kclique(g, 2)
        >>> coms3 = algorithms.label_propagation(g)
        >>> rk = evaluation.ComparisonRanking([coms, coms2, coms3])
        >>> rk.rank(evaluation.overlapping_normalized_mutual_information_LFK)
        >>> rk.rank(evaluation.overlapping_normalized_mutual_information_MGH)
        >>> rk.rank(evaluation.omega)
        >>> rnk, p_value = rk.friedman_ranking()

        :References:

        1. M. Friedman, The use of ranks to avoid the assumption of normality implicit in the analysis of variance, Journal of the American Statistical Association 32 (1937) 674–701.
        2. D.J. Sheskin, Handbook of parametric and nonparametric statistical procedures. crc Press, 2003, Test 25: The Friedman Two-Way Analysis of Variance by Ranks

        """
        ...
    
    def bonferroni_post_hoc(self) -> list:
        """
        Performs a Bonferroni-Dunn post-hoc test using the pivot quantities obtained by a ranking test.
        Tests the hypothesis that the ranking of the control method (best ranked clustering) is different to each of the other methods.

        :return: a list of named tuples reporting the pairwise statistical significant comparisons among the best ranked clustering and the others (in terms of z-value, p-value, adjusted-p-value)

        :Example:

        >>> import networkx as nx
        >>> from cdlib import evaluation
        >>> from cdlib import algorithms
        >>> g = nx.karate_club_graph()
        >>> coms = algorithms.louvain(g)
        >>> coms2 = algorithms.kclique(g, 2)
        >>> coms3 = algorithms.label_propagation(g)
        >>> rk = evaluation.ComparisonRanking([coms, coms2, coms3])
        >>> rk.rank(evaluation.overlapping_normalized_mutual_information_LFK)
        >>> rk.rank(evaluation.overlapping_normalized_mutual_information_MGH)
        >>> rk.rank(evaluation.omega)
        >>> rnk, p_value = rk.friedman_ranking()
        >>> pc = rk.bonferroni_post_hoc()

        :References:

        O.J. Dunn, Multiple comparisons among means, Journal of the American Statistical Association 56 (1961) 52–64.
        """
        ...
    


