"""
This type stub file was generated by pyright.
"""

"""
Created on Wed Jun 20 12:52:55 2018
@author: Vaiva & Tim
"""
__authors__ = ...
__all__ = ["matrix_node_recursive_antichain_partition"]
def is_weakly_connected(graph, source_nodes, target_nodes): # -> bool:
    """
    Tests whether a list of source nodes in a graph have a path in either direction between a list of target nodes.

    Parameters
    ----------
    graph = networkx graph
    source_nodes = list of source nodes for paths
    target_nodes = list of target nodes for paths

    Returns
    -------
    Bool:
        True if there is a path from at least one source node to at least one target node or the other way round
        False otherwise
    """
    ...

class Quality_matrix:
    """
    Quality measures for use in antichains. Similarity matrix implementation.
    """
    def __init__(self, node_id_dict, similarity_matrix, Lambda, with_replacement) -> None:
        ...
    
    def delta_strength_quality_unnormalised(self, partition1, partition2): # -> int:
        """
        Using in-strength null model calculate the change in unnormalised quality if two partitions are combined.

        Definition is that used for weighted graph.

        Q = \sum_{u \in partition1} \sum_{v \in partition2}
            ( S_ij
             - k_i*k_j/W )
        where W = total strength of edges in the graph ((sum_{i,j}S_ij)/2),
        S_{ij} - i,j^th entry in the similarity matrix. For instance, A.A^T is successors-based similarity;
                A^T.A is predecessors-based similarity.

        Note this is not normalised.

        Note no test for connectedness of nodes in partitions.

        Note both partitions must be non-empty otherwise TypeError raised.

        Note no test to see if partitions are sets or if they share common elements.

        Input
        partition1 - iterable list or set of the nodes in first partition
        partition2 - iterable list or set of the nodes in second partition

        Return
        Contribution of the quality Q from the all pairs of nodes with one from partition1, second from partition2
        """
        ...
    
    def quality_one_partition(self, partition): # -> int:
        ...
    
    def total_strength_quality_unnormalised(self, partitions): # -> int:
        """
        Calculate the total unnormalised quality using strength null model

        Definition is that used for weighted graph.

        Q = \sum_{u \in partition1} \sum_{v \in partition2}
            ( S_ij
             - k_i*k_j/W )
        where W = total strength of edges in the graph ((sum_{i,j}S_ij)/2),
        S_{ij} - i,j^th entry in the similarity matrix. For instance, A.A^T is successors-based similarity;
                A^T.A is predecessors-based similarity.

        Note this is not normalised.

        Note no test for connectedness of nodes in partitions.

        Input
        -----
        partition - iterable list of sets of nodes in partitions so that
                    partition[p] is an set (or any iterable list) of the nodes in partition p

        Return
        ------
        Total value of the quality Q from the all pairs of nodes
        """
        ...
    


def get_edge_weight(G, node1, node2, weight_attribute=...): # -> Literal[0, 1]:
    """
    Get Edge Weight

    Returns edge weight for edge in G from node1 to node2
    If edge exists and has weight_attribute, this value is returned.
    If edge exists but has not weight_attribute, 1 is returned.
    Otherwise 0 is returned

    Input
    -----
    G - networkx graph
    node1 - source node
    node2 - target node
    weight_attribute='weight' - attribute of edge containing weight value

    Return
    ------
    edge weight, 1 if edge exists but no weight attribute exists, 0 otherwise.

    """
    ...

def get_node_attribute_value(G, node1, node_attribute=...): # -> float:
    """
    Get Node Attribute Value

    Returns node attribute as a float.
    Otherwise 0.0 is returned

    Input
    -----
    G - networkx graph
    node1 - node
    node_attribute=None - attribute of node required

    Return
    ------
    node attribute as a float

    """
    ...

def is_weakly_connected(graph, source_nodes, target_nodes): # -> bool:
    """
    Tests whether a list of source nodes in a graph have a path in either direction between a list of target nodes.

    Parameters
    ----------
    graph = networkx graph
    source_nodes = list of source nodes for paths
    target_nodes = list of target nodes for paths

    Returns
    -------
    Bool:
        True if there is a path from at least one source node to at least one target node or the other way round
        False otherwise
    """
    ...

def coarse_grain(G, node_to_partition_label, partition_label_to_nodes, weight_attribute=..., time_label=..., space_label=...): # -> DiGraph:
    """
    Coarse Grain

    The new graph H has the partitions of G as the nodes in H.
    An edges from partition1 to partition2 in H is present if
    there is an edge from a node in G in partition1 of G to
    a node in G in partition2.  The total weight of the edge
    from partition1 to partition2 in H will be the sum of all
    the weights of all such edges in G
    from nodes in partition1 to nodes in partition2.
    If unweighted, weights are assumed to be 1.
    If time_label or space_label are set, these are assumed to be numerical
    values (e.g. coordinates) and nodes in the new graph get the average value from
    the partition of nodes they represent in the old graph.


    Input
    ----
    G - networkx graph
    node_to_partition_label - dictionary from G node key to its partition label
    partition_label_to_nodes - dictionary from partition label to the set of nodes in G in that partition
    weight_attribute='weight' - attribute on edge containing edge weight data
    time_label='t': Node key for time coordinate (used as y/vertical coordinate)
    space_label='x': Node key for space coordinate (used as x/horizontal coordinate)

    Return
    ------
    H - coarse grained graph, nodes are the partitions labels, weights are under eight_attribute of edges

    """
    ...

def similarity_matrix(DAG, similarity=..., neighbours=...): # -> tuple[Any, dict[Any, Any]] | None:
    """
    Function to produce a similarity matrix based on neighbourhoods of nodes in DAG.

    Input
    -----
    DAG - networkx directed acyclic graph
    similarity - type of similarity of sets. Currently only implemented for the size of intersection
    neighbours - type of neighbours to consider in the similarity. Can be either successors or predecessors

    Return
    -----
    A - symmetric similarity matrix where entry A[i,j] represents similarity between nodes of indices i, j
    nodedict - dictionary of node names and their indices in the similarity matrix
    """
    ...

def similarity_matrix_sparse(DAG, similarity=..., neighbours=..., with_replacement=...): # -> tuple[Any, dict[Any, Any]] | None:
    """
    Function to produce a sparse similarity matrix based on neighbourhoods of nodes in DAG.

    Input
    -----
    DAG - networkx directed acyclic graph
    similarity - type of similarity of sets. Currently only implemented for the size of intersection
    neighbours - type of neighbours to consider in the similarity. Can be either successors or predecessors or both

    Return
    -----
    A - scipy sparse symmetric similarity matrix where entry A[i,j] represents similarity between nodes of indices i, j
    nodedict - dictionary of node names and their indices in the similarity matrix
    """
    ...

def has_path_matrix(DAG, nodedict, cutoff=...): # -> NDArray[signedinteger[_8Bit]] | Any:
    ...

def find_paths_sparse(A, length_max=...): # -> Any:
    """
    Tim's numpy path implementation updated by Vaiva to sparse matrices
    Scipy sparse matrix implementation to find all paths
    Given adjacency matrix A will find all the paths between all vertices

    Input
    A: numpy square adjacency matrix,can be weighted
    Return
    #tuple current_length,path_length,path_bool where
    #current_length = one more than the maximum length found.
                   If equals length_max then may have terminated because reachd maximum requested length
    #non_zero_entries = number of non-zero entries in P=(A)^current_length
    #path_length = matrix of longest paths lengths
                   path_length[target,source]= longest path from source to target
    path_bool = matrix of booleans indicating if path exists. Paths from vertex to slef (length zero) gives True on diagonal
                   path_bool[target,source]= True (False) if path from source to target
    """
    ...

def is_weakly_connected_matrix(path_matrix, nodedict, source_nodes, target_nodes): # -> bool:
    """
    Function to check whether nodes in the source_nodes are not weakly connected to
    nodes in the target_nodes.

    Input
    -----
    path_matrix - 1/0 matrix where entry P[i,j] = 1 if nodes with indices i,j are weakly connected
    nodedict - dictionary where keys are node names and values are their corresponding indices in the path matrix
    source_nodes - list of nodes
    target_nodes - list of nodes

    Return
    ------
    True - if nodes in source_nodes and target_nodes form a weakly_connected subgraph
    False - if not
    """
    ...

def node_matrix_greedy_antichain_partition(G, level, Lambda, with_replacement, random_on=..., seed=..., max_number_sweeps=..., backwards_forwards_on=..., forwards_backwards_on=..., Q_check_on=..., weight_attribute=...):
    """
    In this implementation we iterate over nodes in the graph moving individual nodes until no changes occur .

    We start with each node in its own partition.
    In one sweep we look at each partition ac in turn.
    We find all the backwards-forwards neighbours of the nodes in partition ac
    and collect all their partition labels, excluding the current partition ac.
    For each of these we find if we can increase the quality function by merging
    current partition ac with one of its bf-neighbouring partitions. If we do we then
    do the merge removing the current partition ac.
    We continue the sweep looking at remaining partitions and trying to merge them.  Note that
    later partitions will see some previous partitions already merged.  The option to randomise the order
    that we visit the partitions will lead to different results.

    After each sweep, if at least one partition was merged then we sweep through again.
    We only stop when no more merges are found on one sweep, or if the number of sweeps exceed
    the maximum requested.

    Note that we do NOT create an explicit hybrid graph. We only use a weakly connected check
    of the

    Input
    -----
    G - networkx graph.
    random_on=False - if true will shuffle the order in which partitions are examined
    seed=None - used as seed if shuffle is on.  If None then time is used as seed
    max_number_sweeps=None - this is the maximum number of sweeps to consider. If less than 1 or None, then uses number of nodes.
    backwards_forwards_on=True  - find possible new partitions by making a backwards step then a forwards step from node being considered for a move
    forwards_backwards_on=False - find possible new partitions by making a forwards step then a backwards step from node being considered for a move
    Q_check_on=False - check to see if change in Q is correct by printing out total value and changes
    weight_attribute - edge attribute of weight. if None, unweighted quality functions are used. Note, weight must be integer

    Return
    ------
    tuple node_to_partition_label, partition_label_to_nodes
    where
    node_to_partition_label is a dictionary from node key to its partition label
    partition_label_to_nodes is a dictionary from partition label to the set of nodes in that partition

    """
    ...

def matrix_node_recursive_antichain_partition(G, time_label=..., space_label=..., random_on=..., seed=..., max_number_sweeps=..., backwards_forwards_on=..., forwards_backwards_on=..., Q_check_on=..., plot_on=..., filenameroot=..., extlist=..., ScreenOn=..., Lambda=..., with_replacement=...): # -> list[Any]:
    """

    Use , **kwargs in func defn and call with kawargs the dictionary for named arguments
    used for the partition

    """
    ...

