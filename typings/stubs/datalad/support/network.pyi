"""
This type stub file was generated by pyright.
"""

import sys

lgr = ...
if sys.version_info >= (3, 7):
    ...
else:
    ...
def is_windows_path(path): # -> bool:
    ...

def get_response_disposition_filename(s): # -> str | None:
    """Given a string s as from HTTP Content-Disposition field in the response
    return possibly present filename if any
    """
    ...

def get_url_disposition_filename(url, headers=...): # -> str | None:
    """Get filename as possibly provided by the server in Content-Disposition
    """
    ...

def get_url_straight_filename(url, strip=..., allowdir=...): # -> str | None:
    """Get file/dir name of the last path component of the URL

    Parameters
    ----------
    strip: list, optional
      If provided, listed names will not be considered and their
      parent directory will be selected
    allowdir: bool, optional
      If url points to a "directory" (ends with /), empty string
      would be returned unless allowdir is True, in which case the
      name of the directory would be returned
    """
    ...

def get_url_filename(url, headers=..., strip=...): # -> str | None:
    """Get filename from the url, first consulting server about Content-Disposition
    """
    ...

def get_url_response_stamp(url, response_info): # -> dict[str, int | None]:
    ...

def get_tld(url):
    """Return top level domain from a url

    Parameters
    ----------
    url : str
    """
    ...

def rfc2822_to_epoch(datestr): # -> int:
    """Given rfc2822 date/time format, return seconds since epoch"""
    ...

def iso8601_to_epoch(datestr): # -> int:
    """Given ISO 8601 date/time format, return in seconds since epoch

    iso8601 is used to parse properly the time zone information, which
    can't be parsed with standard datetime strptime
    """
    ...

def retry_urlopen(url, retries=...): # -> Response | None:
    ...

def is_url_quoted(url): # -> Literal[False]:
    """Return whether URL looks being already quoted
    """
    ...

def same_website(url_rec, u_rec): # -> bool:
    """Decide whether a link leads to external site

    Parameters
    ----------
    url_rec: ParseResult
      record for original url
    u_rec: ParseResult
      record for new url
    """
    ...

def dlurljoin(u_path, url): # -> str:
    ...

class SimpleURLStamper:
    """Gets a simple stamp about the URL: {url, time, size} of whatever was provided in the header
    """
    def __init__(self, mode=...) -> None:
        ...
    
    def __call__(self, url): # -> dict[str, int | None]:
        ...
    


class RI:
    """Resource Identifier - base class and a factory for URL, SSHRI, etc

    Intended to be a R/O object (i.e. no fields should be changed in-place).
    Subclasses define specific collections of fields they care about in _FIELDS
    class variable.
    The idea is that this class should help to break apart a URL, while being
    able to rebuild itself into a string representation for reuse

    `RI` could be used as factory, whenever type of the resource is unknown and
    must be guessed from the string representation.  One of the subclasses will be
    provided as output, e.g.

    >>> RI('http://example.com')
    URL(hostname='example.com', scheme='http')
    >>> RI('example.com:path')
    SSHRI(hostname='example.com', path='path')
    """
    _FIELDS = ...
    __slots__ = ...
    def __new__(cls, ri=..., **kwargs): # -> URL | SSHRI | PathRI | DataLadRI | Self@RI:
        """Used as a possible factory for known RI types

        Returns
        -------
        RI
           uninitialized RI object of appropriate class with _str
           set to string representation if was provided

        """
        ...
    
    def __init__(self, ri=..., **fields) -> None:
        """
        Parameters
        ----------
        ri: str, optional
          String version of a resource specific for this class.  If you would like
          a type of the resource be deduced, use RI(ri)
        **fields: dict, optional
          The values for the fields defined in _FIELDS class variable.
        """
        ...
    
    @property
    def fields(self): # -> OrderedDict[Literal['path'], Unknown | str]:
        """Returns shallow copy of fields to ease manipulations"""
        ...
    
    def __repr__(self): # -> str:
        ...
    
    def __str__(self) -> str:
        ...
    
    @classmethod
    def from_str(cls, ri_str): # -> Self@RI:
        ...
    
    @property
    def localpath(self):
        ...
    
    def __bool__(self): # -> bool:
        ...
    
    def __eq__(self, other) -> bool:
        ...
    
    def __ne__(self, other) -> bool:
        ...
    
    def __getattribute__(self, item): # -> Any | str:
        ...
    
    def __setattr__(self, item, value): # -> None:
        ...
    


class URL(RI):
    """Universal resource locator

    Although largely decorating urlparse.ParseResult, it
    - doesn't mandate providing all parts of the URL
    - doesn't require netloc but rather asks for separate username, password, and hostname
    """
    _FIELDS = ...
    def as_str(self): # -> AnyStr@_ParseResultBase:
        """Render URL as a string"""
        ...
    
    def to_pr(self): # -> ParseResult:
        """Convert URL to urlparse.ParseResults namedtuple"""
        ...
    
    @property
    def query_dict(self): # -> dict[Unknown, Unknown] | OrderedDict[Unknown, Unknown]:
        ...
    
    @property
    def fragment_dict(self): # -> dict[Unknown, Unknown] | OrderedDict[Unknown, Unknown]:
        ...
    
    @property
    def localpath(self): # -> Any | str:
        ...
    


class PathRI(RI):
    """RI pointing to a (local) file/directory"""
    def as_str(self): # -> Any | str:
        ...
    
    @property
    def localpath(self): # -> Any | str:
        ...
    
    @property
    def posixpath(self): # -> Any | str:
        ...
    


class RegexBasedURLMixin:
    """Base class for URLs which we could simple parse using regular expressions"""
    _REGEX = ...


class SSHRI(RI, RegexBasedURLMixin):
    """RI pointing to a remote location reachable via SSH"""
    _FIELDS = ...
    _REGEX = ...
    def as_str(self, escape=...): # -> LiteralString:
        ...
    


class DataLadRI(RI, RegexBasedURLMixin):
    """RI pointing to datasets within default DataLad super-dataset"""
    _FIELDS = ...
    _REGEX = ...
    def as_str(self): # -> LiteralString:
        ...
    
    def as_git_url(self): # -> str:
        """Dereference /// into original URLs which could be used by git for cloning

        Returns
        -------
        str
          URL string to reference the DataLadRI from its /// form
        """
        ...
    


_SSH_ESCAPED_CHARACTERS = ...
def escape_ssh_path(path):
    """Escape all special characters present in the path"""
    ...

def unescape_ssh_path(path):
    """Un-escape all special characters present in the path"""
    ...

def parse_url_opts(url): # -> tuple[str, dict[Unknown, Unknown] | OrderedDict[Unknown, Unknown]]:
    """Given a string with url-style query, split into content before # and options as dict"""
    ...

def is_url(ri): # -> bool:
    """Returns whether argument is a resource identifier what datalad should treat as a URL

    This includes ssh "urls" which git understands.

    Parameters
    ----------
    ri : str or RI
      The resource identifier (as a string or RI) to "analyze"
    """
    ...

def is_datalad_compat_ri(ri): # -> bool:
    """Returns whether argument is a resource identifier what datalad should treat as a URL

    including its own DataLadRI
    """
    ...

def is_ssh(ri): # -> Any | bool:
    """helper to determine, whether `ri` requires an SSH connection

    Parameters
    ----------
    ri: str or RI

    Returns
    -------
    bool
    """
    ...

def get_local_file_url(fname, compatibility=...): # -> str:
    """Return OS specific URL pointing to a local file

    Parameters
    ----------
    fname : string
        Filename.  If not absolute, abspath is used
    compatibility : {'git', 'git-annex'}, optional
        On Windows, and only on that platform, file:// URLs may need to look
        different depending on the use case or consuming application. This
        switch selects different compatibility modes: 'git' for use with
        Git commands (e.g. `clone` or `submodule add`); 'git-annex` for
        Git-annex command input (e.g. `addurl`). On any other platform this
        setting has no effect.
    """
    ...

def get_url_cache_filename(url, name=...): # -> str:
    """Return a filename where to cache online doc from a url"""
    ...

def get_cached_url_content(url, name=..., fetcher=..., maxage=...): # -> Any:
    """Loader of a document from a url, which caches loaded instance on disk

    Doesn't do anything smart about http headers etc which could provide
    information for cache/proxy servers for how long to retain etc

    TODO: theoretically it is not network specific at all -- and just a memoize
    pattern, but may be some time we would make it treat headers etc correctly.
    And ATM would support any URL we support via providers/downloaders

    Parameters
    ----------
    fetcher: callable, optional
       Function to call with url if needed to be refetched
    maxage: float, optional
       Age in days to retain valid for.  <0 - would retain forever.  If None -
       would consult the config, 0 - would force to reload
    """
    ...

